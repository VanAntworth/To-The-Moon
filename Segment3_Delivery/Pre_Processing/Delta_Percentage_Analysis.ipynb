{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f9c078",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dd8d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database related all the code is moved to this file\n",
    "%run -i \"SqlConn.py\"\n",
    "#importing local py file\n",
    "import SqlConn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4576bf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetch Tweets and Sentiment data - Join from Tweet and Sentiment tables\n",
    "try:\n",
    "    df_dbSentimentData = SqlConn.fetchTweetSentimentForStandardizing(\"\")\n",
    "    print(\"Data transfer Done\")\n",
    "except BaseException as err:\n",
    "    print(err)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49934e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetch Tweets and Sentiment data - Join from Tweet and Sentiment tables\n",
    "try:\n",
    "    df_dbFinaceData = SqlConn.fetchFinanceData(\"\")\n",
    "    print(\"Data transfer Done\")\n",
    "except BaseException as err:\n",
    "    print(err)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a303db95",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_full = df_dbSentimentData\n",
    "tweets_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5bcfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_full['tweetID'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd38647",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_full[(tweets_full['tweetID'] == 1022430321696858112)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73df1139",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_full.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05e2c67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8401d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_full['date'] = pd.to_datetime(tweets_full['date'])\n",
    "tweets_full = tweets_full.sort_values(['date'], ascending = True)\n",
    "tweets_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0550fd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_full['date'] = tweets_full['date'].dt.date\n",
    "tweets_full['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a3b416",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_full.set_index('tweetID', inplace=True)\n",
    "tweets_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a308466",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_filtered_twitter_df = tweets_full[(tweets_full[\"financeType\"] == \"twitter\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc51678",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_filtered_tesla_df = tweets_full[(tweets_full[\"financeType\"] == \"tesla\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ed9fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_filtered_doge_df = tweets_full[(tweets_full[\"financeType\"] == \"doge\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7162e034",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_dates_twitter = pd.to_datetime(tweets_filtered_twitter_df['date'])\n",
    "tweet_dates_twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a46725",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_dates_tesla = pd.to_datetime(tweets_filtered_tesla_df['date'])\n",
    "tweet_dates_tesla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f67e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_dates_doge = pd.to_datetime(tweets_filtered_doge_df['date'])\n",
    "tweet_dates_doge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201d8525",
   "metadata": {},
   "outputs": [],
   "source": [
    "Stock_Data = df_dbFinaceData\n",
    "Stock_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cd5639",
   "metadata": {},
   "outputs": [],
   "source": [
    "Stock_Data_Twitter_df = Stock_Data[(Stock_Data[\"financeType\"] == \"twitter\")]\n",
    "Stock_Data_Twitter_df.reset_index(inplace=True)\n",
    "Stock_Data_Twitter_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f986fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Stock_Data_Tesla_df = Stock_Data[(Stock_Data[\"financeType\"] == \"tesla\")]\n",
    "Stock_Data_Tesla_df.reset_index(inplace=True)\n",
    "Stock_Data_Tesla_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73260d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Stock_Data_Doge_df = Stock_Data[(Stock_Data[\"financeType\"] == \"doge\")]\n",
    "Stock_Data_Doge_df.reset_index(inplace=True)\n",
    "Stock_Data_Doge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d08c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "Stock_Data_Twitter_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95a2cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Stock_Data_Tesla_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1dbea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Stock_Data_Doge_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2883bfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Stock_Data_Twitter_df['date'] =  pd.to_datetime(Stock_Data_Twitter_df['date'])\n",
    "Stock_Data_Tesla_df['date'] =  pd.to_datetime(Stock_Data_Tesla_df['date'])\n",
    "Stock_Data_Doge_df['date'] =  pd.to_datetime(Stock_Data_Doge_df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8fe464",
   "metadata": {},
   "outputs": [],
   "source": [
    "Stock_Data_Doge_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c537c073",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finance_tweet_relationship(tweet_dates,finance_stock_df):\n",
    "\n",
    "\n",
    "    stock_price_per_tweet = {}\n",
    "    start_date_dic = {}\n",
    "    \n",
    "    finance_tweets_df = pd.DataFrame()\n",
    "    Dates_df = []\n",
    "    Adj_Close_df = []\n",
    "    Volume_df = []\n",
    "    finance_ids_df = []\n",
    "    Date_Position_df = []\n",
    "    tweet_ids_df = []\n",
    "    tweet_date_df = []\n",
    "        \n",
    "    \n",
    "\n",
    "    for tweet_id in tweet_dates.index:\n",
    "            start_date = tweet_dates[tweet_id] - datetime.timedelta(days=1)\n",
    "\n",
    "            print (f'working on {tweet_id} with start date {start_date}')\n",
    "\n",
    "            for i in range(len(finance_stock_df['date'])):\n",
    "\n",
    "                Dates = []\n",
    "                Adj_Close = []\n",
    "                Volume = []\n",
    "                df = pd.DataFrame()\n",
    "\n",
    "                if start_date == finance_stock_df['date'][i]:\n",
    "                    j=i\n",
    "                    n=0\n",
    "                    \n",
    "                    end_date = start_date + datetime.timedelta(days=7)\n",
    "                    print(f'this is my end date {end_date}')\n",
    "\n",
    "                    while finance_stock_df['date'][j]<=end_date and j <= (len(finance_stock_df['date'])-2):\n",
    "\n",
    "                        Dates.append(finance_stock_df['date'][j])\n",
    "                        Adj_Close.append(finance_stock_df['adjustedClose'][j])\n",
    "                        Volume.append(finance_stock_df['volume'][j])\n",
    "                        \n",
    "                        \n",
    "                        Dates_df.append(finance_stock_df['date'][j])\n",
    "                        Adj_Close_df.append(finance_stock_df['adjustedClose'][j])\n",
    "                        Volume_df.append(finance_stock_df['volume'][j])\n",
    "                        finance_ids_df.append(finance_stock_df['id'][j])\n",
    "                        Date_Position_df.append(n)\n",
    "                        tweet_date_df.append(tweet_dates[tweet_id])\n",
    "                        tweet_ids_df.append(tweet_id) \n",
    "                                            \n",
    "                        \n",
    "                        j+=1\n",
    "                        n+=1\n",
    "                        \n",
    "                    df = pd.DataFrame(\n",
    "                        {'date':Dates,\n",
    "                         'adjustedClose': Adj_Close,\n",
    "                         'volume':Volume}\n",
    "                    ) \n",
    "\n",
    "\n",
    "                    stock_price_per_tweet[tweet_id] = df\n",
    "                    start_date_dic[tweet_id] = start_date\n",
    "\n",
    "                    print (df)\n",
    "\n",
    "                    break\n",
    "\n",
    "                elif start_date < finance_stock_df['date'][i]:\n",
    "\n",
    "                    start_date = finance_stock_df['date'][i-1]\n",
    "                    print (f'start date changed to {start_date}')\n",
    "                    \n",
    "                    j=i-1\n",
    "                    n=0\n",
    "                    \n",
    "                    end_date = start_date + datetime.timedelta(days=7)\n",
    "                    print(f'this is my new end date {end_date}')\n",
    "\n",
    "                    while finance_stock_df['date'][j]<=end_date and j <= (len(finance_stock_df['date'])-2) :\n",
    "                        \n",
    "                        Dates.append(finance_stock_df['date'][j])\n",
    "                        Adj_Close.append(finance_stock_df['adjustedClose'][j])\n",
    "                        Volume.append(finance_stock_df['volume'][j])\n",
    "                        \n",
    "                        Dates_df.append(finance_stock_df['date'][j])\n",
    "                        Adj_Close_df.append(finance_stock_df['adjustedClose'][j])\n",
    "                        Volume_df.append(finance_stock_df['volume'][j])\n",
    "                        finance_ids_df.append(finance_stock_df['id'][j])\n",
    "                        Date_Position_df.append(n)\n",
    "                        tweet_date_df.append(tweet_dates[tweet_id])\n",
    "                        tweet_ids_df.append(tweet_id) \n",
    "                                             \n",
    "                        \n",
    "                        j+=1\n",
    "                        n+=1\n",
    "                        \n",
    "                    df = pd.DataFrame(\n",
    "                        {'date':Dates,\n",
    "                         'adjustedClose': Adj_Close,\n",
    "                         'volume':Volume}\n",
    "                    ) \n",
    "\n",
    "                    stock_price_per_tweet[tweet_id] = df\n",
    "                    start_date_dic[tweet_id] = start_date\n",
    "                    \n",
    "                    start_date=0\n",
    "\n",
    "                    print (df)\n",
    "\n",
    "                    break\n",
    "\n",
    "                else: \n",
    "                    print(f'I am in {i}')\n",
    "        \n",
    "    finance_tweets_df = pd.DataFrame(\n",
    "            {'tweetID':tweet_ids_df,\n",
    "             'tweetDate':tweet_date_df,\n",
    "             \n",
    "             'financeID':finance_ids_df,\n",
    "             'financeDate':Dates_df,\n",
    "             'adjustedClose': Adj_Close_df,\n",
    "             'volume':Volume_df,\n",
    "             'datePosition':Date_Position_df}\n",
    "        \n",
    "    )\n",
    "                    \n",
    "    return stock_price_per_tweet, finance_tweets_df, start_date_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e5b26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_price_per_tweet_twitter, twitter_tweets_finance_dates_df, start_date_dic_twitter = finance_tweet_relationship(tweet_dates_twitter,Stock_Data_Twitter_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bf8c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_price_per_tweet_tesla, tesla_tweets_finance_dates_df, start_date_dic_tesla = finance_tweet_relationship(tweet_dates_tesla,Stock_Data_Tesla_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedd2305",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_price_per_tweet_doge, doge_tweets_finance_dates_df, start_date_dic_doge = finance_tweet_relationship(tweet_dates_doge,Stock_Data_Doge_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ec31f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deltas (df):\n",
    "    Delta_Adj_Close = []\n",
    "    Percent_Adj_Close=[]\n",
    "    Delta_Volume = []\n",
    "    Percent_Volume = []\n",
    "    df_delta = pd.DataFrame()\n",
    "    \n",
    "    for i in range(len(df['date'])-1):\n",
    "        \n",
    "        Delta_Adj_Close.append(df['adjustedClose'][i+1]-df['adjustedClose'][0])\n",
    "        Percent_Adj_Close.append(((df['adjustedClose'][i+1]-df['adjustedClose'][0])/df['adjustedClose'][0])*100)\n",
    "        Delta_Volume.append(df['volume'][i+1]-df['volume'][0])\n",
    "        Percent_Volume.append(((df['volume'][i+1]-df['volume'][0])/df['volume'][0])*100)\n",
    "        \n",
    "    df_delta = pd.DataFrame(\n",
    "            {'Delta Adj Close':Delta_Adj_Close,\n",
    "             'Percent Adj Close':Percent_Adj_Close,\n",
    "             'Delta Volume': Delta_Volume,\n",
    "             'Percent Volume':Percent_Volume}\n",
    "                ) \n",
    "\n",
    "    \n",
    "    return (df_delta)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849bcf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_per_tweet_twitter = {}\n",
    "\n",
    "for key in stock_price_per_tweet_twitter.keys():\n",
    "    \n",
    "    delta_per_tweet_twitter[key]= deltas(stock_price_per_tweet_twitter[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434bef37",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_per_tweet_tesla = {}\n",
    "\n",
    "for key in stock_price_per_tweet_tesla.keys():\n",
    "    \n",
    "    delta_per_tweet_tesla[key]= deltas(stock_price_per_tweet_tesla[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2ad6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_per_tweet_tesla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e89191b",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_per_tweet_doge = {}\n",
    "\n",
    "for key in stock_price_per_tweet_doge.keys():\n",
    "    \n",
    "    delta_per_tweet_doge[key]= deltas(stock_price_per_tweet_doge[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a99d0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta_toDataFrame(delta_per_tweet):   \n",
    "    tweet_id = []\n",
    "\n",
    "    delta_adj_0 = []\n",
    "    delta_adj_1 = []\n",
    "    delta_adj_2 = []\n",
    "    delta_adj_3 = []\n",
    "    delta_adj_4 = []\n",
    "    delta_adj_5 = []\n",
    "    delta_adj_6 = []\n",
    "    delta_adj_7 = []\n",
    "\n",
    "    per_adj_0 = []\n",
    "    per_adj_1 = []\n",
    "    per_adj_2 = []\n",
    "    per_adj_3 = []\n",
    "    per_adj_4 = []\n",
    "    per_adj_5 = []\n",
    "    per_adj_6 = []\n",
    "    per_adj_7 = []\n",
    "\n",
    "    delta_vol_0 = []\n",
    "    delta_vol_1 = []\n",
    "    delta_vol_2 = []\n",
    "    delta_vol_3 = []\n",
    "    delta_vol_4 = []\n",
    "    delta_vol_5 = []\n",
    "    delta_vol_6 = []\n",
    "    delta_vol_7 = []\n",
    "\n",
    "    per_vol_0 = []\n",
    "    per_vol_1 = []\n",
    "    per_vol_2 = []\n",
    "    per_vol_3 = []\n",
    "    per_vol_4 = []\n",
    "    per_vol_5 = []\n",
    "    per_vol_6 = []\n",
    "    per_vol_7 = []\n",
    "\n",
    "    for key in delta_per_tweet.keys():\n",
    "\n",
    "        tweet_id.append(key)\n",
    "        \n",
    "        if delta_per_tweet[key].empty:\n",
    "\n",
    "            delta_adj_0.append(0)\n",
    "            per_adj_0.append(0)\n",
    "            delta_vol_0.append(0)\n",
    "            per_vol_0.append(0)\n",
    "\n",
    "            delta_adj_1.append(0)\n",
    "            per_adj_1.append(0)\n",
    "            delta_vol_1.append(0)\n",
    "            per_vol_1.append(0)\n",
    "\n",
    "\n",
    "            delta_adj_2.append(0)\n",
    "            per_adj_2.append(0)\n",
    "            delta_vol_2.append(0)\n",
    "            per_vol_2.append(0)       \n",
    "        \n",
    "            delta_adj_3.append(0)\n",
    "            per_adj_3.append(0)\n",
    "            delta_vol_3.append(0)\n",
    "            per_vol_3.append(0)\n",
    "            \n",
    "            delta_adj_4.append(0)\n",
    "            per_adj_4.append(0)\n",
    "            delta_vol_4.append(0)\n",
    "            per_vol_4.append(0)\n",
    "            \n",
    "            delta_adj_5.append(0)\n",
    "            per_adj_5.append(0)\n",
    "            delta_vol_5.append(0)\n",
    "            per_vol_5.append(0)\n",
    "            \n",
    "            delta_adj_6.append(0)\n",
    "            per_adj_6.append(0)\n",
    "            delta_vol_6.append(0)\n",
    "            per_vol_6.append(0)\n",
    "            \n",
    "            delta_adj_7.append(0)\n",
    "            per_adj_7.append(0)\n",
    "            delta_vol_7.append(0)\n",
    "            per_vol_7.append(0)            \n",
    "        \n",
    "        else:\n",
    "\n",
    "            delta_adj_0.append(delta_per_tweet[key]['Delta Adj Close'][0])\n",
    "            per_adj_0.append(delta_per_tweet[key]['Percent Adj Close'][0])\n",
    "            delta_vol_0.append(delta_per_tweet[key]['Delta Volume'][0])\n",
    "            per_vol_0.append(delta_per_tweet[key]['Percent Volume'][0])\n",
    "\n",
    "            delta_adj_1.append(delta_per_tweet[key]['Delta Adj Close'][1])\n",
    "            per_adj_1.append(delta_per_tweet[key]['Percent Adj Close'][1])\n",
    "            delta_vol_1.append(delta_per_tweet[key]['Delta Volume'][1])\n",
    "            per_vol_1.append(delta_per_tweet[key]['Percent Volume'][1])\n",
    "\n",
    "            if len(delta_per_tweet[key]['Delta Adj Close']) >= 3:\n",
    "\n",
    "                delta_adj_2.append(delta_per_tweet[key]['Delta Adj Close'][2])\n",
    "                per_adj_2.append(delta_per_tweet[key]['Percent Adj Close'][2])\n",
    "                delta_vol_2.append(delta_per_tweet[key]['Delta Volume'][2])\n",
    "                per_vol_2.append(delta_per_tweet[key]['Percent Volume'][2])\n",
    "\n",
    "                if len(delta_per_tweet[key]['Delta Adj Close']) >= 4:\n",
    "\n",
    "                    delta_adj_3.append(delta_per_tweet[key]['Delta Adj Close'][3])\n",
    "                    per_adj_3.append(delta_per_tweet[key]['Percent Adj Close'][3])\n",
    "                    delta_vol_3.append(delta_per_tweet[key]['Delta Volume'][3])\n",
    "                    per_vol_3.append(delta_per_tweet[key]['Percent Volume'][3])\n",
    "\n",
    "                    if len(delta_per_tweet[key]['Delta Adj Close']) >= 5:\n",
    "\n",
    "                        delta_adj_4.append(delta_per_tweet[key]['Delta Adj Close'][4])\n",
    "                        per_adj_4.append(delta_per_tweet[key]['Percent Adj Close'][4])\n",
    "                        delta_vol_4.append(delta_per_tweet[key]['Delta Volume'][4])\n",
    "                        per_vol_4.append(delta_per_tweet[key]['Percent Volume'][4])\n",
    "\n",
    "                        if len(delta_per_tweet[key]['Delta Adj Close']) >= 6:\n",
    "\n",
    "                            delta_adj_5.append(delta_per_tweet[key]['Delta Adj Close'][5])\n",
    "                            per_adj_5.append(delta_per_tweet[key]['Percent Adj Close'][5])\n",
    "                            delta_vol_5.append(delta_per_tweet[key]['Delta Volume'][5])\n",
    "                            per_vol_5.append(delta_per_tweet[key]['Percent Volume'][5])\n",
    "\n",
    "                            if len(delta_per_tweet[key]['Delta Adj Close']) >= 7:\n",
    "\n",
    "                                delta_adj_6.append(delta_per_tweet[key]['Delta Adj Close'][6])\n",
    "                                per_adj_6.append(delta_per_tweet[key]['Percent Adj Close'][6])\n",
    "                                delta_vol_6.append(delta_per_tweet[key]['Delta Volume'][6])\n",
    "                                per_vol_6.append(delta_per_tweet[key]['Percent Volume'][6])\n",
    "\n",
    "                                if len(delta_per_tweet[key]['Delta Adj Close']) >= 8:\n",
    "\n",
    "                                    delta_adj_7.append(delta_per_tweet[key]['Delta Adj Close'][7])\n",
    "                                    per_adj_7.append(delta_per_tweet[key]['Percent Adj Close'][7])\n",
    "                                    delta_vol_7.append(delta_per_tweet[key]['Delta Volume'][7])\n",
    "                                    per_vol_7.append(delta_per_tweet[key]['Percent Volume'][7])\n",
    "\n",
    "                                else:\n",
    "                                    delta_adj_7.append(0)\n",
    "                                    per_adj_7.append(0)\n",
    "                                    delta_vol_7.append(0)\n",
    "                                    per_vol_7.append(0)\n",
    "\n",
    "                            else:\n",
    "\n",
    "                                delta_adj_7.append(0)\n",
    "                                per_adj_7.append(0)\n",
    "                                delta_vol_7.append(0)\n",
    "                                per_vol_7.append(0)\n",
    "\n",
    "                                delta_adj_6.append(0)\n",
    "                                per_adj_6.append(0)\n",
    "                                delta_vol_6.append(0)\n",
    "                                per_vol_6.append(0) \n",
    "\n",
    "                        else:\n",
    "\n",
    "                            delta_adj_7.append(0)\n",
    "                            per_adj_7.append(0)\n",
    "                            delta_vol_7.append(0)\n",
    "                            per_vol_7.append(0)\n",
    "\n",
    "                            delta_adj_6.append(0)\n",
    "                            per_adj_6.append(0)\n",
    "                            delta_vol_6.append(0)\n",
    "                            per_vol_6.append(0) \n",
    "\n",
    "                            delta_adj_5.append(0)\n",
    "                            per_adj_5.append(0)\n",
    "                            delta_vol_5.append(0)\n",
    "                            per_vol_5.append(0)                     \n",
    "\n",
    "                    else:\n",
    "\n",
    "                        delta_adj_7.append(0)\n",
    "                        per_adj_7.append(0)\n",
    "                        delta_vol_7.append(0)\n",
    "                        per_vol_7.append(0)\n",
    "\n",
    "                        delta_adj_6.append(0)\n",
    "                        per_adj_6.append(0)\n",
    "                        delta_vol_6.append(0)\n",
    "                        per_vol_6.append(0) \n",
    "\n",
    "                        delta_adj_5.append(0)\n",
    "                        per_adj_5.append(0)\n",
    "                        delta_vol_5.append(0)\n",
    "                        per_vol_5.append(0) \n",
    "\n",
    "                        delta_adj_4.append(0)\n",
    "                        per_adj_4.append(0)\n",
    "                        delta_vol_4.append(0)\n",
    "                        per_vol_4.append(0)\n",
    "\n",
    "                else:\n",
    "\n",
    "                    delta_adj_7.append(0)\n",
    "                    per_adj_7.append(0)\n",
    "                    delta_vol_7.append(0)\n",
    "                    per_vol_7.append(0)\n",
    "\n",
    "                    delta_adj_6.append(0)\n",
    "                    per_adj_6.append(0)\n",
    "                    delta_vol_6.append(0)\n",
    "                    per_vol_6.append(0) \n",
    "\n",
    "                    delta_adj_5.append(0)\n",
    "                    per_adj_5.append(0)\n",
    "                    delta_vol_5.append(0)\n",
    "                    per_vol_5.append(0)\n",
    "\n",
    "                    delta_adj_4.append(0)\n",
    "                    per_adj_4.append(0)\n",
    "                    delta_vol_4.append(0)\n",
    "                    per_vol_4.append(0)                \n",
    "\n",
    "                    delta_adj_3.append(0)\n",
    "                    per_adj_3.append(0)\n",
    "                    delta_vol_3.append(0)\n",
    "                    per_vol_3.append(0)\n",
    "\n",
    "            else:\n",
    "\n",
    "                delta_adj_7.append(0)\n",
    "                per_adj_7.append(0)\n",
    "                delta_vol_7.append(0)\n",
    "                per_vol_7.append(0)\n",
    "\n",
    "                delta_adj_6.append(0)\n",
    "                per_adj_6.append(0)\n",
    "                delta_vol_6.append(0)\n",
    "                per_vol_6.append(0) \n",
    "\n",
    "                delta_adj_5.append(0)\n",
    "                per_adj_5.append(0)\n",
    "                delta_vol_5.append(0)\n",
    "                per_vol_5.append(0)\n",
    "\n",
    "                delta_adj_4.append(0)\n",
    "                per_adj_4.append(0)\n",
    "                delta_vol_4.append(0)\n",
    "                per_vol_4.append(0)                \n",
    "\n",
    "                delta_adj_3.append(0)\n",
    "                per_adj_3.append(0)\n",
    "                delta_vol_3.append(0)\n",
    "                per_vol_3.append(0)\n",
    "                \n",
    "                delta_adj_2.append(0)\n",
    "                per_adj_2.append(0)\n",
    "                delta_vol_2.append(0)\n",
    "                per_vol_2.append(0)\n",
    "\n",
    "\n",
    "\n",
    "    deltas_df = pd.DataFrame(\n",
    "                    {\n",
    "                        'tweetID':tweet_id,\n",
    "\n",
    "                        'deltaPrice_0':delta_adj_0,\n",
    "                        'deltaPrice_1':delta_adj_1,\n",
    "                        'deltaPrice_2':delta_adj_2,\n",
    "                        'deltaPrice_3':delta_adj_3,\n",
    "                        'deltaPrice_4':delta_adj_4,\n",
    "                        'deltaPrice_5':delta_adj_5,\n",
    "                        'deltaPrice_6':delta_adj_6,\n",
    "                        'deltaPrice_7':delta_adj_7,                        \n",
    "\n",
    "                        'percentPrice_0':per_adj_0,\n",
    "                        'percentPrice_1':per_adj_1,\n",
    "                        'percentPrice_2':per_adj_2,\n",
    "                        'percentPrice_3':per_adj_3,\n",
    "                        'percentPrice_4':per_adj_4,\n",
    "                        'percentPrice_5':per_adj_5,\n",
    "                        'percentPrice_6':per_adj_6,\n",
    "                        'percentPrice_7':per_adj_7,                        \n",
    "\n",
    "                        'deltaVol_0':delta_vol_0,\n",
    "                        'deltaVol_1':delta_vol_1,\n",
    "                        'deltaVol_2':delta_vol_2,\n",
    "                        'deltaVol_3':delta_vol_3,\n",
    "                        'deltaVol_4':delta_vol_4,\n",
    "                        'deltaVol_5':delta_vol_5,\n",
    "                        'deltaVol_6':delta_vol_6,\n",
    "                        'deltaVol_7':delta_vol_7,                        \n",
    "\n",
    "                        'percentVol_0':per_vol_0,\n",
    "                        'percentVol_1':per_vol_1,\n",
    "                        'percentVol_2':per_vol_2,\n",
    "                        'percentVol_3':per_vol_3,\n",
    "                        'percentVol_4':per_vol_4,\n",
    "                        'percentVol_5':per_vol_5,\n",
    "                        'percentVol_6':per_vol_6,\n",
    "                        'percentVol_7':per_vol_7                        \n",
    "\n",
    "                    })\n",
    "    \n",
    "    return deltas_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a343706",
   "metadata": {},
   "outputs": [],
   "source": [
    "deltas_twitter_df = delta_toDataFrame(delta_per_tweet_twitter) \n",
    "deltas_twitter_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c48d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "deltas_tesla_df = delta_toDataFrame(delta_per_tweet_tesla)\n",
    "deltas_tesla_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0596e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "deltas_doge_df = delta_toDataFrame(delta_per_tweet_doge)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fd4741",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_dateToFrame(start_date_dic):    \n",
    "    tweet_id = []\n",
    "    start_date = []\n",
    "\n",
    "    for key in start_date_dic.keys():\n",
    "        tweet_id.append(key)\n",
    "        start_date.append(start_date_dic[key])\n",
    "\n",
    "    start_date_df = pd.DataFrame(\n",
    "                {'tweetID':tweet_id,\n",
    "                 'startDate':start_date}\n",
    "                    ) \n",
    "\n",
    "    return start_date_df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb097e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date_twitter_df = start_dateToFrame(start_date_dic_twitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7289b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date_tesla_df = start_dateToFrame(start_date_dic_tesla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc20ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date_doge_df = start_dateToFrame(start_date_dic_doge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4d3f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date_twitter_df.set_index('tweetID', inplace=True)\n",
    "start_date_tesla_df.set_index('tweetID', inplace=True)\n",
    "start_date_doge_df.set_index('tweetID', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46f4221",
   "metadata": {},
   "outputs": [],
   "source": [
    "deltas_twitter_df.set_index('tweetID', inplace=True)\n",
    "deltas_tesla_df.set_index('tweetID', inplace=True)\n",
    "deltas_doge_df.set_index('tweetID', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b2a0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_twitter_df = tweets_filtered_twitter_df.join(start_date_twitter_df)\n",
    "int_tesla_df = tweets_filtered_tesla_df.join(start_date_tesla_df)\n",
    "int_doge_df = tweets_filtered_doge_df.join(start_date_doge_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc20c496",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_twitter_df = int_twitter_df.join(deltas_twitter_df)\n",
    "final_tesla_df = int_tesla_df.join(deltas_tesla_df)\n",
    "final_doge_df = int_doge_df.join(deltas_doge_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e510c65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_twitter_df['date'] = pd.to_datetime(final_twitter_df['date'])\n",
    "final_tesla_df['date'] = pd.to_datetime(final_tesla_df['date'])\n",
    "final_doge_df['date'] = pd.to_datetime(final_doge_df['date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c682db",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_twitter_df['datesDifference'] = final_twitter_df['date']-final_twitter_df['startDate']\n",
    "final_tesla_df['datesDifference'] = final_tesla_df['date']-final_tesla_df['startDate']\n",
    "final_doge_df['datesDifference'] = final_doge_df['date']-final_doge_df['startDate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20f00d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_twitter_df['weekendOrHoliday'] = (final_twitter_df['datesDifference']>'1d')\n",
    "final_tesla_df['weekendOrHoliday'] = (final_tesla_df['datesDifference']>'1d')\n",
    "final_doge_df['weekendOrHoliday'] = (final_doge_df['datesDifference']>'1d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee57360a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8189d960",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_tesla_df['financeType']='tesla'\n",
    "final_twitter_df['financeType']='twitter'\n",
    "final_doge_df['financeType']='doge'\n",
    "\n",
    "df_deltas_tostore = pd.concat([final_tesla_df, final_twitter_df, final_doge_df],axis=0,ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5d7e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deltas_tostore.reset_index(inplace=True)\n",
    "df_deltas_tostore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0123448f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deltas_tostore = df_deltas_tostore.drop('replyCount', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd06924c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deltas_tostore['datesDifference'] = df_deltas_tostore['datesDifference'].dt.days.astype('int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d924e0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deltas_tostore.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087f58f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_deltas_tostore.to_csv('deltas_tostore.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318502c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla_tweets_finance_dates_df['financeType']='tesla'\n",
    "twitter_tweets_finance_dates_df['financeType']='twitter'\n",
    "doge_tweets_finance_dates_df['financeType']='doge'\n",
    "\n",
    "df_financetweet_tostore = pd.concat([tesla_tweets_finance_dates_df,twitter_tweets_finance_dates_df,doge_tweets_finance_dates_df],axis=0,ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff90773",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_financetweet_tostore.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3190059",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_financetweet_tostore.to_csv('financetweet_tostore.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8304fb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Tweet data\n",
    "\n",
    "try:\n",
    "    SqlConn.insertDeltas(df_deltas_tostore)\n",
    "    SqlConn.insertFinanceTweetForecast(df_financetweet_tostore)\n",
    "    print(\"Data Transfer Done\")\n",
    "except BaseException as err:\n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdc6423",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_twitter_df['startDate'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b7f4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_tesla_df['startDate'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e34a1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_doge_df['startDate'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470eb24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert startdate groupby code once everything with SQL works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23eb79f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_sum_columns = {\n",
    "          \n",
    "#       \"likesCount\": 'sum',\n",
    "#       \"retweetCount\": 'sum',\n",
    "#       \"sentimentScore\" : 'sum',\n",
    "      \n",
    "#       \"tweetID\" : 'count',\n",
    "            \n",
    "#       \"percentPrice_0\" : 'mean',\n",
    "#       \"percentPrice_1\" : 'mean',\n",
    "#       \"percentPrice_2\" : 'mean',\n",
    "#       \"percentPrice_3\" : 'mean',\n",
    "#       \"percentPrice_4\" : 'mean'\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36593e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_average_columns = {\n",
    "          \n",
    "#       \"likesCount\": 'mean',\n",
    "#       \"retweetCount\": 'mean',\n",
    "#       \"sentimentScore\" : 'mean',\n",
    "      \n",
    "#       \"tweetID\" : 'count',\n",
    "            \n",
    "#       \"percentPrice_0\" : 'mean',\n",
    "#       \"percentPrice_1\" : 'mean',\n",
    "#       \"percentPrice_2\" : 'mean',\n",
    "#       \"percentPrice_3\" : 'mean',\n",
    "#       \"percentPrice_4\" : 'mean'\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3ec52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deltas_Twitter_df = df_deltas_tostore[(df_deltas_tostore[\"financeType\"] == \"twitter\")]\n",
    "# deltas_Tesla_df = df_deltas_tostore[(df_deltas_tostore[\"financeType\"] == \"tesla\")]\n",
    "# deltas_Doge_df = df_deltas_tostore[(df_deltas_tostore[\"financeType\"] == \"doge\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c687c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_twitter_df_average = deltas_Twitter_df.groupby('startDate').agg(model_average_columns)\n",
    "# model_tesla_df_average = deltas_Tesla_df.groupby('startDate').agg(model_average_columns)\n",
    "# model_doge_df_average = deltas_Doge_df.groupby('startDate').agg(model_average_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65857310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_twitter_df_sum = deltas_Twitter_df.groupby('startDate').agg(model_sum_columns)\n",
    "# model_tesla_df_sum = deltas_Tesla_df.groupby('startDate').agg(model_sum_columns)\n",
    "# model_doge_df_sum = deltas_Doge_df.groupby('startDate').agg(model_sum_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a5f54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split data into testing and training sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(df_AdjustedClose[['adjustedClose']], df_AdjustedClose[['EMA_10']], test_size=.2)\n",
    "# # Test set\n",
    "# print(X_test.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f203c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "# # Create Regression Model\n",
    "# model = LinearRegression()\n",
    "# # Train the model\n",
    "# model.fit(X_train, y_train)\n",
    "# # Use model to make predictions\n",
    "# y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc847ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "# # Printout relevant metrics\n",
    "# print(\"Model Coefficients:\", model.coef_)\n",
    "# print(\"Mean Absolute Error:\", mean_absolute_error(y_test, y_pred))\n",
    "# print(\"Coefficient of Determination:\", r2_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
