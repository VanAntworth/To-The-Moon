{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d95eef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17b90156",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import unicodedata\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "from config import db_password\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f500e4f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_engine' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_52148/108899873.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Fetch sentiment data from Postgres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdb_string\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"postgresql://postgres:{db_password}@localhost:5432/ElonMuskTwitterImpact\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mengine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdb_string\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mquery_String\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'SELECT \"twitterID\", \"date\", \"closingPrice\", volumn, \"sentimentScore\", sentiment FROM \"SentimentScoring\"'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf_dbSentimentData\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_sql\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery_String\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'create_engine' is not defined"
     ]
    }
   ],
   "source": [
    "# Fetch sentiment data from Postgres \n",
    "db_string = f\"postgresql://postgres:{db_password}@localhost:5432/ElonMuskTwitterImpact\"\n",
    "engine = create_engine(db_string)\n",
    "query_String = 'SELECT \"twitterID\", \"date\", \"closingPrice\", volumn, \"sentimentScore\", sentiment FROM \"SentimentScoring\"'\n",
    "df_dbSentimentData = pd.read_sql(query_String, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2aa14490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the csv files containin the tweets by Eon Musk from 2010 to 2022 for DogeCOin, Tesla, spaceX, twitter.\n",
    "df_doge = pd.read_csv('../Data_Resources/scrapped_data/doge_tweets.csv')\n",
    "df_spaceX = pd.read_csv('../Data_Resources/scrapped_data/spaceX_tweets.csv')\n",
    "df_tesla = pd.read_csv('../Data_Resources/scrapped_data/tesla_tweets.csv')\n",
    "df_twitter = pd.read_csv('../Data_Resources/scrapped_data/twitter_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21add833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of doge df: (68, 8)\n",
      "shape of spaceX df: (602, 8)\n",
      "shape of tesla df: (1486, 8)\n",
      "shape of twitter df: (89, 8)\n"
     ]
    }
   ],
   "source": [
    "print(f\"shape of doge df: \" + str(df_doge.shape))\n",
    "print(f\"shape of spaceX df: \" + str(df_spaceX.shape))\n",
    "print(f\"shape of tesla df: \" + str(df_tesla.shape))\n",
    "print(f\"shape of twitter df: \" + str(df_twitter.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94455c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_doge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0799c55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spaceX.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba280fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tesla.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b545d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4acc67d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c44fa83",
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mvader_lexicon\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('vader_lexicon')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93msentiment/vader_lexicon.zip/vader_lexicon/vader_lexicon.txt\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\15125/nltk_data'\n    - 'C:\\\\Users\\\\15125\\\\anaconda3\\\\envs\\\\PythonData\\\\nltk_data'\n    - 'C:\\\\Users\\\\15125\\\\anaconda3\\\\envs\\\\PythonData\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\15125\\\\anaconda3\\\\envs\\\\PythonData\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\15125\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - ''\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_47988/33400486.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSentimentIntensityAnalyzer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\nltk\\sentiment\\vader.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, lexicon_file)\u001b[0m\n\u001b[0;32m    338\u001b[0m         \u001b[0mlexicon_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"sentiment/vader_lexicon.zip/vader_lexicon/vader_lexicon.txt\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m     ):\n\u001b[1;32m--> 340\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlexicon_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlexicon_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlexicon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_lex_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstants\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVaderConstants\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[0;32m    748\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    749\u001b[0m     \u001b[1;31m# Load the resource.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 750\u001b[1;33m     \u001b[0mopened_resource\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    751\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    752\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"raw\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(resource_url)\u001b[0m\n\u001b[0;32m    874\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    875\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"nltk\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 876\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    877\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"file\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    878\u001b[0m         \u001b[1;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"*\"\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mvader_lexicon\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('vader_lexicon')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93msentiment/vader_lexicon.zip/vader_lexicon/vader_lexicon.txt\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\15125/nltk_data'\n    - 'C:\\\\Users\\\\15125\\\\anaconda3\\\\envs\\\\PythonData\\\\nltk_data'\n    - 'C:\\\\Users\\\\15125\\\\anaconda3\\\\envs\\\\PythonData\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\15125\\\\anaconda3\\\\envs\\\\PythonData\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\15125\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - ''\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "vader = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7aa9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_doge_vader = df_doge.copy()\n",
    "df_spaceX_vader = df_spaceX.copy()\n",
    "df_tesla_vader = df_tesla.copy()\n",
    "df_twitter_vader = df_twitter.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd5806c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_doge_vader[\"normalized\"] = df_doge_vader[\"Tweet\"].apply(lambda tweet:unicodedata.normalize('NFKD', tweet))\n",
    "df_doge_vader[\"compound_sc\"] = df_doge_vader[\"Tweet\"].apply(lambda tweet: vader.polarity_scores(tweet)[\"compound\"])\n",
    "df_doge_vader[\"negative_sc\"] = df_doge_vader[\"Tweet\"].apply(lambda tweet: vader.polarity_scores(tweet)[\"neg\"])\n",
    "df_doge_vader[\"neutral_sc\"] = df_doge_vader[\"Tweet\"].apply(lambda tweet: vader.polarity_scores(tweet)[\"neu\"])\n",
    "df_doge_vader[\"positive_sc\"] = df_doge_vader[\"Tweet\"].apply(lambda tweet: vader.polarity_scores(tweet)[\"pos\"])\n",
    "df_doge_vader.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7959841e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_doge_vader[\"normalized\"] = df_doge_vader[\"Tweet\"].apply(lambda tweet:unicodedata.normalize('NFKD', tweet))\n",
    "df_spaceX_vader[\"compound_sc\"] = df_spaceX_vader[\"Tweet\"].apply(lambda tweet: vader.polarity_scores(tweet)[\"compound\"])\n",
    "df_spaceX_vader[\"negative_sc\"] = df_spaceX_vader[\"Tweet\"].apply(lambda tweet: vader.polarity_scores(tweet)[\"neg\"])\n",
    "df_spaceX_vader[\"neutral_sc\"] = df_spaceX_vader[\"Tweet\"].apply(lambda tweet: vader.polarity_scores(tweet)[\"neu\"])\n",
    "df_spaceX_vader[\"positive_sc\"] = df_spaceX_vader[\"Tweet\"].apply(lambda tweet: vader.polarity_scores(tweet)[\"pos\"])\n",
    "df_spaceX_vader.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467ac979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_doge_vader[\"normalized\"] = df_doge_vader[\"Tweet\"].apply(lambda tweet:unicodedata.normalize('NFKD', tweet))\n",
    "df_tesla_vader[\"compound_sc\"] = df_tesla_vader[\"Tweet\"].apply(lambda tweet: vader.polarity_scores(tweet)[\"compound\"])\n",
    "df_tesla_vader[\"negative_sc\"] = df_tesla_vader[\"Tweet\"].apply(lambda tweet: vader.polarity_scores(tweet)[\"neg\"])\n",
    "df_tesla_vader[\"neutral_sc\"] = df_tesla_vader[\"Tweet\"].apply(lambda tweet: vader.polarity_scores(tweet)[\"neu\"])\n",
    "df_tesla_vader[\"positive_sc\"] = df_tesla_vader[\"Tweet\"].apply(lambda tweet: vader.polarity_scores(tweet)[\"pos\"])\n",
    "df_tesla_vader.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a438233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_doge_vader[\"normalized\"] = df_doge_vader[\"Tweet\"].apply(lambda tweet:unicodedata.normalize('NFKD', tweet))\n",
    "df_twitter_vader[\"compound_sc\"] = df_twitter_vader[\"Tweet\"].apply(lambda tweet: vader.polarity_scores(tweet)[\"compound\"])\n",
    "df_twitter_vader[\"negative_sc\"] = df_twitter_vader[\"Tweet\"].apply(lambda tweet: vader.polarity_scores(tweet)[\"neg\"])\n",
    "df_twitter_vader[\"neutral_sc\"] = df_twitter_vader[\"Tweet\"].apply(lambda tweet: vader.polarity_scores(tweet)[\"neu\"])\n",
    "df_twitter_vader[\"positive_sc\"] = df_twitter_vader[\"Tweet\"].apply(lambda tweet: vader.polarity_scores(tweet)[\"pos\"])\n",
    "df_twitter_vader.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b47293",
   "metadata": {},
   "source": [
    "### Sentiment Analysis by TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbee5101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to get the subjectivity\n",
    "def getSubjectivity(text):\n",
    "    return TextBlob(text).sentiment.subjectivity\n",
    "\n",
    "# Create a function to get the polarity\n",
    "def getPolarity(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "# Create a function to compute the negative, neutral, and positive analysis\n",
    "def getAnalysis(score):\n",
    "    if score < 0:\n",
    "        return \"Negative\"\n",
    "    elif score == 0:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Positive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63d021f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'getSubjectivity' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_47988/1371835073.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Create 2 new columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdf_doge_txtblb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"subjectivity\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_doge_txtblb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Tweet\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetSubjectivity\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mdf_doge_txtblb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"polarity\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_doge_txtblb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Tweet\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetPolarity\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mdf_doge_txtblb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Sentiment'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_doge_txtblb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'polarity'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetAnalysis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'getSubjectivity' is not defined"
     ]
    }
   ],
   "source": [
    "#Make a copy of the df_doge df\n",
    "df_doge_txtblb = df_doge.copy()\n",
    "\n",
    "# Create 2 new columns\n",
    "df_doge_txtblb[\"subjectivity\"] = df_doge_txtblb[\"Tweet\"].apply(getSubjectivity)\n",
    "df_doge_txtblb[\"polarity\"] = df_doge_txtblb[\"Tweet\"].apply(getPolarity)\n",
    "df_doge_txtblb['Sentiment'] = df_doge_txtblb['polarity'].apply(getAnalysis)\n",
    "df_doge_txtblb.head()\n",
    "df_doge_txtblb.to_csv(\"filename.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122dd7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_doge_txtblb[\"Sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f96e082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the polarity and subjectivity \n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(df_doge_txtblb[\"polarity\"],df_doge_txtblb[\"subjectivity\"], color = 'Blue')\n",
    "plt.title(\"Sentiment Analysis\")\n",
    "plt.xlabel(\"Polarity\")\n",
    "plt.ylabel(\"Subjectivity\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f741206",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a copy of the df_spaceX df\n",
    "df_spaceX_txtblb = df_spaceX.copy()\n",
    "\n",
    "# Create 2 new columns\n",
    "df_spaceX_txtblb[\"subjectivity\"] = df_spaceX_txtblb[\"Tweet\"].apply(getSubjectivity)\n",
    "df_spaceX_txtblb[\"polarity\"] = df_spaceX_txtblb[\"Tweet\"].apply(getPolarity)\n",
    "df_spaceX_txtblb['Sentiment'] = df_spaceX_txtblb['polarity'].apply(getAnalysis)\n",
    "df_spaceX_txtblb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d998eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spaceX_txtblb[\"Sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1fbba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the polarity and subjectivity \n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(df_spaceX_txtblb[\"polarity\"],df_spaceX_txtblb[\"subjectivity\"], color = 'Blue')\n",
    "plt.title(\"Sentiment Analysis\")\n",
    "plt.xlabel(\"Polarity\")\n",
    "plt.ylabel(\"Subjectivity\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c5333a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a copy of the df_tesla df\n",
    "df_tesla_txtblb = df_tesla.copy()\n",
    "\n",
    "# Create 2 new columns\n",
    "df_tesla_txtblb[\"subjectivity\"] = df_tesla_txtblb[\"Tweet\"].apply(getSubjectivity)\n",
    "df_tesla_txtblb[\"polarity\"] = df_tesla_txtblb[\"Tweet\"].apply(getPolarity)\n",
    "df_tesla_txtblb['Sentiment'] = df_tesla_txtblb['polarity'].apply(getAnalysis)\n",
    "df_tesla_txtblb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2bf529",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tesla_txtblb[\"Sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b189269e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the polarity and subjectivity \n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(df_tesla_txtblb[\"polarity\"],df_tesla_txtblb[\"subjectivity\"], color = 'Blue')\n",
    "plt.title(\"Sentiment Analysis\")\n",
    "plt.xlabel(\"Polarity\")\n",
    "plt.ylabel(\"Subjectivity\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ebf3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a copy of the df_twitter df\n",
    "df_twitter_txtblb = df_twitter.copy()\n",
    "\n",
    "# Create 2 new columns\n",
    "df_twitter_txtblb[\"subjectivity\"] = df_twitter_txtblb[\"Tweet\"].apply(getSubjectivity)\n",
    "df_twitter_txtblb[\"polarity\"] = df_twitter_txtblb[\"Tweet\"].apply(getPolarity)\n",
    "df_twitter_txtblb['Sentiment'] = df_twitter_txtblb['polarity'].apply(getAnalysis)\n",
    "df_twitter_txtblb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213a9998",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter_txtblb[\"Sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed4feee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the polarity and subjectivity \n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(df_twitter_txtblb[\"polarity\"],df_twitter_txtblb[\"subjectivity\"], color = 'Blue')\n",
    "plt.title(\"Sentiment Analysis\")\n",
    "plt.xlabel(\"Polarity\")\n",
    "plt.ylabel(\"Subjectivity\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08508e75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149b2b4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514824d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
